{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ssh_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQONLE0DdLel",
        "colab_type": "code",
        "outputId": "ec952f77-fc26-487e-a10a-1126416a4977",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "236sAD_NN__B",
        "colab_type": "text"
      },
      "source": [
        "4/rgHEaMr3f0PaCeiq4AIdOMVrp40Wdv7cZjt-yrILocRGG1E9EAK4kvQ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlbVc9YLZV5n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "818da836-5909-4859-c437-ceafa2bd63b3"
      },
      "source": [
        "!nvidia-smi\n",
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Oct  1 07:30:22 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.40       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy0J9xTwOZW4",
        "colab_type": "text"
      },
      "source": [
        "1RaQqFMOIFOujEbYvexR6we6vx4_hNLeP4HfLQBc5sKN3fXc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYLI2UwrZz1t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "3f99a9f8-aeed-47c2-92ea-5a9b0ee87d93"
      },
      "source": [
        "#Generate root password\n",
        "import random, string\n",
        "password = ''.join(random.choice(string.ascii_letters + string.digits) for i in range(20))\n",
        "\n",
        "#Download ngrok\n",
        "! wget -q -c -nc https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "! unzip -qq -n ngrok-stable-linux-amd64.zip\n",
        "#Setup sshd\n",
        "! apt-get install -qq -o=Dpkg::Use-Pty=0 openssh-server pwgen > /dev/null\n",
        "#Set root password\n",
        "! echo root:$password | chpasswd\n",
        "! mkdir -p /var/run/sshd\n",
        "! echo \"PermitRootLogin yes\" >> /etc/ssh/sshd_config\n",
        "! echo \"PasswordAuthentication yes\" >> /etc/ssh/sshd_config\n",
        "! echo \"LD_LIBRARY_PATH=/usr/lib64-nvidia\" >> /root/.bashrc\n",
        "! echo \"export LD_PRELOAD=/usr/lib64-nvidia/libnvidia-ml.so\" >> /root/.bashrc\n",
        "! echo \"export LD_LIBRARY_PATH\" >> /root/.bashrc\n",
        "! echo \"export PATH=/usr/local/cuda-10.0/bin${PATH:+:${PATH}}$\" >> /root/.bashrc\n",
        "! echo \"export LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\" >> /root/.bashrc\n",
        "\n",
        "#Run sshd\n",
        "get_ipython().system_raw('/usr/sbin/sshd -D &')\n",
        "\n",
        "#Ask token\n",
        "print(\"Copy authtoken from https://dashboard.ngrok.com/auth\")\n",
        "import getpass\n",
        "authtoken = getpass.getpass()\n",
        "\n",
        "#Create tunnel\n",
        "get_ipython().system_raw('./ngrok authtoken $authtoken && ./ngrok tcp 22 &')\n",
        "#Print root password\n",
        "print(\"Root password: {}\".format(password))\n",
        "#Get public address\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copy authtoken from https://dashboard.ngrok.com/auth\n",
            "··········\n",
            "Root password: DiG8wj2OHifDmE5jveCk\n",
            "tcp://0.tcp.ngrok.io:14336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwiPRoJ4o6cB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! yes | cp -rf /content/drive/'My Drive'/OKOK/custom/.bashrc /root/.bashrc\n",
        "#! yes | cp -rf /content/drive/'My Drive'/OKOK/custom/.gitconfig /root"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDslm7HtMwtS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd4957a7-3405-4975-cd3b-dea4b9136c15"
      },
      "source": [
        "%cd /content/drive/\"My Drive\"/OKOK/my_alexeyAB"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/OKOK/my_alexeyAB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73GeuGswM2OQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "outputId": "424eb25a-89f3-41ef-c8c7-ecad4bf1695e"
      },
      "source": [
        "!./train.sh"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "yolov3-tiny_xnor_person\n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv     16       3 x 3/ 1    416 x 416 x   3 ->  416 x 416 x  16 0.150 BF\n",
            "   1 max               2 x 2/ 2    416 x 416 x  16 ->  208 x 208 x  16 0.003 BF\n",
            "   2 convXB   32       3 x 3/ 1    208 x 208 x  16 ->  208 x 208 x  32 0.399 BF\n",
            "   3 max               2 x 2/ 2    208 x 208 x  32 ->  104 x 104 x  32 0.001 BF\n",
            "   4 convXB   64       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  64 0.399 BF\n",
            "   5 max               2 x 2/ 2    104 x 104 x  64 ->   52 x  52 x  64 0.001 BF\n",
            "   6 convXB  128       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x 128 0.399 BF\n",
            "   7 max               2 x 2/ 2     52 x  52 x 128 ->   26 x  26 x 128 0.000 BF\n",
            "   8 convX   256       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 256 0.399 BF\n",
            "   9 max               2 x 2/ 2     26 x  26 x 256 ->   13 x  13 x 256 0.000 BF\n",
            "  10 convXB  512       3 x 3/ 1     13 x  13 x 256 ->   13 x  13 x 512 0.399 BF\n",
            "  11 max               2 x 2/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.000 BF\n",
            "  12 convXB 1024       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x1024 1.595 BF\n",
            "  13 convX   256       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x 256 0.089 BF\n",
            "  14 conv    512       3 x 3/ 1     13 x  13 x 256 ->   13 x  13 x 512 0.399 BF\n",
            "  15 conv     18       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x  18 0.003 BF\n",
            "  16 yolo\n",
            "[yolo] params: iou loss: mse, iou_norm: 0.75, cls_norm: 1.00, scale_x_y: 1.00\n",
            "  17 route  13\n",
            "  18 convX   128       1 x 1/ 1     13 x  13 x 256 ->   13 x  13 x 128 0.011 BF\n",
            "  19 upsample                 2x    13 x  13 x 128 ->   26 x  26 x 128\n",
            "  20 route  19 8\n",
            "  21 convX   256       3 x 3/ 1     26 x  26 x 384 ->   26 x  26 x 256 1.196 BF\n",
            "  22 conv     18       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x  18 0.006 BF\n",
            "  23 yolo\n",
            "[yolo] params: iou loss: mse, iou_norm: 0.75, cls_norm: 1.00, scale_x_y: 1.00\n",
            "Total BFLOPS 5.448 \n",
            " Allocate additional workspace_size = 111.80 MB \n",
            "Loading weights from backup/yolov3-tiny_xnor_person_last.weights...\n",
            " seen 64 \n",
            "Done! Loaded 24 layers from weights-file \n",
            "Learning Rate: 0.001, Momentum: 0.9, Decay: 0.0005\n",
            "Resizing\n",
            "608 x 608 \n",
            " try to allocate additional workspace_size = 238.81 MB \n",
            " CUDA allocate done! \n",
            "Loaded: 6.946925 seconds\n",
            "CUDA status Error: file: ./src/blas_kernels.cu : () : line: 668 : build time: Oct  1 2019 - 07:35:03 \n",
            "CUDA Error: no kernel image is available for execution on the device\n",
            "CUDA Error: no kernel image is available for execution on the device: File exists\n",
            "darknet: ./src/utils.c:293: error: Assertion `0' failed.\n",
            "./train.sh: line 1:  1975 Aborted                 (core dumped) ./darknet detector train build/yolov3_custom/darknet.data build/yolov3_custom/yolov3-tiny_xnor_person.cfg backup/yolov3-tiny_xnor_person_last.weights -gpus 0 -dont_show\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5AAmCNtQ9z_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "12a565fe-0b64-4a26-d0f6-c2744b4238a2"
      },
      "source": [
        "!git reset --hard"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking out files: 100% (3572/3572), done.\n",
            "HEAD is now at 2573238 edit cfg lap 2000 000 lan\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}